# CS224N Milestone Plan

This document translates the TA guidance into a concrete evaluation plan for this repo.

## Quick Verdict On Your Current Procedure

Your current testing procedure is mostly correct. Keep it, with these fixes:

1. `left` and `right` are **turns**, not directional moves with distance.  
   Values map to angles: `10->15째`, `30->45째`, `60->90째`, `100->180째`.
2. Include a **control split** for compositional generalization (`held_control`) in addition to `held_test`.
3. Include **tool-only metrics** (ignore values) in addition to exact `(tool,value)` metrics.
4. Use **greedy decoding** (`temperature=0`) for reported numbers.
5. Keep a simple baseline:
   - random program baseline
   - optional oracle sanity check
6. For TA guidance, do zero/few-shot baselines across pretrained models first, then pick one model for finetuning.

## Milestone Questions You Should Answer

1. Can a pretrained model output valid action programs?
2. Does few-shot prompting improve tool-sequence generation?
3. Can SFT solve IID mapping well?
4. Does performance drop on length and held-out composition splits?
5. Is drop on `held_test` larger than `held_control` (evidence of compositional weakness)?

## Required Splits

Generated by `src/splits.py`:

- `iid_train`, `iid_dev`, `iid_test`
- `len_train`, `len_test`
- `held_train`, `held_test`, `held_control`

## Recommended Experiment Matrix

1. Random baseline:
   - test: `iid_test`, `len_test`, `held_test`, `held_control`
2. Pretrained zero-shot (`num_shots=0`):
   - models: `Qwen/Qwen3-0.6B`, `Qwen/Qwen3-1.7B`, `Qwen/Qwen3-4B` (or instruct variants)
   - same four test splits
3. Pretrained few-shot (`num_shots=4` from `iid_train`):
   - same models, same four test splits
4. Chosen model SFT on IID:
   - train: `iid_train` (dev: `iid_dev`)
   - test: `iid_test`, `len_test`, `held_test`, `held_control`
5. Compositional-focused SFT:
   - train: `held_train`
   - test: `held_test` and `held_control`
6. Length-focused SFT:
   - train: `len_train`
   - test: `len_test`

## Metrics To Report

Primary:

- `exact_match`
- `step_f1` (tool+value)
- `tool_step_f1` (tool-only)
- `valid_rate`

Diagnostic:

- `parseable_rate`
- `tool_exact_match`
- `tool_edit_dist`
- `length_acc`
- `invalid_reasons`

## Commands

## 0) Setup

```bash
python3 -m venv .venv
source .venv/bin/activate
pip install --upgrade pip
pip install torch transformers accelerate
mkdir -p data outputs
```

## 1) Generate data + splits

```bash
python3 -m src.data_gen \
  --out data/synth.jsonl \
  --n_programs 6000 \
  --k_paraphrases 3 \
  --min_len 1 \
  --max_len 4 \
  --seed 0

python3 -m src.splits \
  --infile data/synth.jsonl \
  --outdir data \
  --seed 0 \
  --iid_train 14000 \
  --iid_dev 2000 \
  --iid_test 2000
```

## 2) Random baseline

```bash
python3 -m src.make_baseline_preds --gold data/iid_test.jsonl --out data/preds_random_iid.jsonl --mode random --seed 0
python3 -m src.score_predictions --gold data/iid_test.jsonl --pred data/preds_random_iid.jsonl --out_json outputs/random_iid.json
```

Repeat for `len_test`, `held_test`, `held_control`.

## 3) Pretrained zero/few-shot baselines (Qwen sweep)

```bash
python3 -m src.run_milestone_eval \
  --models Qwen/Qwen3-0.6B,Qwen/Qwen3-1.7B,Qwen/Qwen3-4B \
  --tests data/iid_test.jsonl,data/len_test.jsonl,data/held_test.jsonl,data/held_control.jsonl \
  --fewshot_path data/iid_train.jsonl \
  --num_shots_list 0,4 \
  --constrained 1 \
  --temperature 0.0 \
  --out outputs/pretrained_matrix.jsonl
```

To compare multiple models, pass comma-separated names in `--models`.

## 4) SFT on IID

```bash
python3 -m src.train_sft \
  --model gpt2 \
  --train data/iid_train.jsonl \
  --dev data/iid_dev.jsonl \
  --out outputs/sft_iid \
  --epochs 1 \
  --lr 5e-5 \
  --bsz 2 \
  --grad_accum 16 \
  --max_length 128
```

Evaluate:

```bash
python3 -m src.run_milestone_eval \
  --models outputs/sft_iid \
  --tests data/iid_test.jsonl,data/len_test.jsonl,data/held_test.jsonl,data/held_control.jsonl \
  --num_shots_list 0 \
  --constrained 1 \
  --temperature 0.0 \
  --out outputs/sft_iid_matrix.jsonl
```

## 5) SFT on held and len special splits

Held:

```bash
python3 -m src.train_sft --model gpt2 --train data/held_train.jsonl --dev data/iid_dev.jsonl --out outputs/sft_held --epochs 1 --lr 5e-5 --bsz 2 --grad_accum 16 --max_length 128
python3 -m src.run_milestone_eval --models outputs/sft_held --tests data/held_test.jsonl,data/held_control.jsonl --num_shots_list 0 --constrained 1 --temperature 0.0 --out outputs/sft_held_matrix.jsonl
```

Length:

```bash
python3 -m src.train_sft --model gpt2 --train data/len_train.jsonl --dev data/iid_dev.jsonl --out outputs/sft_len --epochs 1 --lr 5e-5 --bsz 2 --grad_accum 16 --max_length 128
python3 -m src.run_milestone_eval --models outputs/sft_len --tests data/len_test.jsonl --num_shots_list 0 --constrained 1 --temperature 0.0 --out outputs/sft_len_matrix.jsonl
```

## Report Table Template

Use one row per `(model, train_split, test_split, shots)`:

- Model
- Train split (`none` for pretrained)
- Test split
- Shots
- Constrained decoding (0/1)
- Valid rate
- Exact match
- Step F1
- Tool-step F1
- Tool edit distance

## Division Of Labor

Suggested split based on your note:

1. You: run commands above and produce result tables/figures.
2. Teammate: write abstract + approach section.
3. You: write experiments + error analysis section from generated JSON metrics.
